import os
import datetime as dt
import requests
import psycopg2
from psycopg2.extras import execute_values
from dotenv import load_dotenv

load_dotenv()

# ========== iiko ==========
IIKO_BASE_URL = (os.getenv("IIKO_BASE_URL", "") or "").strip().rstrip("/")
IIKO_LOGIN = os.getenv("IIKO_LOGIN")
IIKO_PASSWORD = os.getenv("IIKO_PASSWORD")

DEPARTMENTS = ["–ê–≤–∏–∞–≥–æ—Ä–æ–¥–æ–∫", "–î–æ–º–æ–¥–µ–¥–æ–≤–æ"]
PRODUCT_NUM_FILTER = [
    "0722",
    "45700042712",
    "45700042362",
    "45700041658",
    "45700042237",
    "45700042841",
    "45700042013",
    "25551",
    "45700042089",
    "0603",
    "45700042183",
    "0607",
    "45700041955",
    "06163",
    "4570004177",
    "45700041757",
    "0617",
    "45700041956",
    "45700042665",
    "45700041625",
    "45700041762",
    "2313231233122312335",
    "00001",
    "00002",
    "00003",
]  # –µ—Å–ª–∏ –Ω–µ –Ω—É–∂–µ–Ω ‚Äî —Å–¥–µ–ª–∞–π []


# ---------- helpers for iiko urls ----------
def _join(base: str, path: str) -> str:
    return base.rstrip("/") + "/" + path.lstrip("/")


def iiko_api_url(path: str, use_resto: bool) -> str:
    """
    use_resto=True  -> BASE/resto/<path>
    use_resto=False -> BASE/<path>
    """
    base = IIKO_BASE_URL
    if use_resto:
        if base.endswith("/resto"):
            return _join(base, path)
        return _join(base, "/resto/" + path.lstrip("/"))
    return _join(base, path)


def request_with_resto_fallback(method: str, path: str, **kwargs):
    """
    –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º BASE/<path>, –µ—Å–ª–∏ 404 ‚Äî –ø—Ä–æ–±—É–µ–º BASE/resto/<path>.
    """
    if not IIKO_BASE_URL:
        raise RuntimeError("IIKO_BASE_URL is not set")

    url1 = iiko_api_url(path, use_resto=False)
    resp = requests.request(method, url1, **kwargs)

    if resp.status_code == 404:
        url2 = iiko_api_url(path, use_resto=True)
        resp2 = requests.request(method, url2, **kwargs)
        return resp2, url2

    return resp, url1


# ========== Postgres (Neon) ==========
def get_pg_connection():
    return psycopg2.connect(
        host=os.getenv("PG_HOST"),
        port=os.getenv("PG_PORT"),
        dbname=os.getenv("PG_DB"),
        user=os.getenv("PG_USER"),
        password=os.getenv("PG_PASSWORD"),
        sslmode=os.getenv("PG_SSLMODE", "require"),
    )


# ========== Period ==========
def get_period():
    date_from_str = os.getenv("DATE_FROM")
    date_to_str = os.getenv("DATE_TO")

    if date_from_str and date_to_str:
        date_from = dt.date.fromisoformat(date_from_str)
        date_to = dt.date.fromisoformat(date_to_str)
        print(f"üìÖ –ü–µ—Ä–∏–æ–¥ –∏–∑ ENV: {date_from} ‚Äî {date_to}")
        return date_from, date_to

    LOOKBACK_DAYS = int(os.getenv("LOOKBACK_DAYS", "7"))

    today = dt.date.today()
    date_from = today - dt.timedelta(days=LOOKBACK_DAYS)
    date_to = today

    print(f"üìÖ –ü–µ—Ä–∏–æ–¥ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–ø–æ—Å–ª–µ–¥–Ω–∏–µ {LOOKBACK_DAYS} –¥–Ω–µ–π): {date_from} ‚Äî {date_to}")
    return date_from, date_to


# ========== Auth ==========
def get_token() -> str:
    if not IIKO_LOGIN or not IIKO_PASSWORD:
        raise RuntimeError("IIKO_LOGIN / IIKO_PASSWORD is not set")

    resp, used_url = request_with_resto_fallback(
        "GET",
        "/api/auth",
        params={"login": IIKO_LOGIN, "pass": IIKO_PASSWORD},
        timeout=30,
    )
    print(f"üåê AUTH URL: {used_url}")
    resp.raise_for_status()

    token = resp.text.strip()
    print(f"üîë –¢–æ–∫–µ–Ω –ø–æ–ª—É—á–µ–Ω: {token[:6]}...")
    return token


def logout(token: str):
    if not token:
        return
    try:
        resp, used_url = request_with_resto_fallback(
            "POST",
            "/api/logout",
            params={"key": token},
            timeout=10,
        )
        print(f"üåê LOGOUT URL: {used_url} ({resp.status_code})")
    except Exception as e:
        print("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ logout:", e)


# ========== iiko OLAP ==========
def fetch_stock_tx(token: str, date_from: dt.date, date_to: dt.date):
    print("üì¶ –ó–∞–≥—Ä—É–∂–∞–µ–º OLAP '–û—Ç—á–µ—Ç –ø–æ –ø—Ä–æ–≤–æ–¥–∫–∞–º' –∏–∑ iiko...")

    filters = {
        "DateTime.OperDayFilter": {
            "filterType": "DateRange",
            "periodType": "CUSTOM",
            "from": date_from.strftime("%Y-%m-%d"),
            "to": date_to.strftime("%Y-%m-%d"),
            "includeLow": True,
            "includeHigh": False,  # –í–ê–ñ–ù–û: oper_day < date_to
        },
        "Department": {
            "filterType": "IncludeValues",
            "values": DEPARTMENTS,
        },
    }

    if PRODUCT_NUM_FILTER:
        filters["Product.Num"] = {
            "filterType": "IncludeValues",
            "values": PRODUCT_NUM_FILTER,
        }

    body = {
        "reportType": "TRANSACTIONS",
        "groupByRowFields": [
            "DateTime.DateTyped",
            "Product.Num",
            "Product.Name",
            "Department",
            "Product.Type",
            "Product.MeasureUnit",
            "Document",
            "TransactionType",
        ],
        "aggregateFields": ["Amount.StoreInOutTyped"],
        "filters": filters,
    }

    resp, used_url = request_with_resto_fallback(
        "POST",
        "/api/v2/reports/olap",
        params={"key": token},
        json=body,
        timeout=90,
    )
    print(f"üåê OLAP URL: {used_url}")
    resp.raise_for_status()

    data = resp.json()
    rows = []
    for r in data.get("data", []):
        oper_raw = r.get("DateTime.DateTyped")
        oper_day = oper_raw[:10] if isinstance(oper_raw, str) else oper_raw

        rows.append(
            {
                "department": r.get("Department"),
                "oper_day": oper_day,
                "product_num": r.get("Product.Num"),
                "product_name": r.get("Product.Name"),
                "product_type": r.get("Product.Type"),
                "measure_unit": r.get("Product.MeasureUnit"),
                "document": r.get("Document"),
                "transaction_type": r.get("TransactionType"),
                "turnover": float(r.get("Amount.StoreInOutTyped") or 0),
            }
        )

    print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ —Å—Ç—Ä–æ–∫ –∏–∑ iiko: {len(rows)}")
    print("üîé –ü–µ—Ä–≤—ã–µ 10 —Å—Ç—Ä–æ–∫ –∏–∑ iiko:")
    for i, x in enumerate(rows[:10], start=1):
        print(f"{i:02d}. {x}")

    return rows


# ========== DB schema helpers ==========
def get_table_columns(conn, table_name: str, schema: str = "public") -> set[str]:
    q = """
        SELECT column_name
        FROM information_schema.columns
        WHERE table_schema = %s AND table_name = %s;
    """
    with conn.cursor() as cur:
        cur.execute(q, (schema, table_name))
        return {r[0] for r in cur.fetchall()}


def table_exists(conn, table_name: str, schema: str = "public") -> bool:
    q = """
        SELECT EXISTS (
            SELECT 1
            FROM information_schema.tables
            WHERE table_schema = %s AND table_name = %s
        );
    """
    with conn.cursor() as cur:
        cur.execute(q, (schema, table_name))
        return bool(cur.fetchone()[0])


def pick_turnover_column(cols: set[str]) -> str:
    for cand in ("turnover", "store_in_out", "amount_store_in_out", "amount"):
        if cand in cols:
            return cand
    raise RuntimeError(
        "–ù–µ –Ω–∞—à—ë–ª –∫–æ–ª–æ–Ω–∫—É –ø–æ–¥ –æ–±–æ—Ä–æ—Ç. –û–∂–∏–¥–∞–ª –æ–¥–Ω—É –∏–∑: turnover / store_in_out / amount_store_in_out / amount"
    )


def aggregate_rows(rows: list[dict], with_document: bool) -> list[dict]:
    key_fields = ["department", "oper_day", "product_num", "product_name", "product_type", "measure_unit"]
    if with_document:
        key_fields.append("document")
    key_fields.append("transaction_type")

    agg = {}
    for r in rows:
        key = tuple(r.get(k) for k in key_fields)
        if key not in agg:
            agg[key] = dict(r)
        else:
            agg[key]["turnover"] = float(agg[key].get("turnover") or 0) + float(r.get("turnover") or 0)

    out = list(agg.values())
    print(f"üìå –ü–æ—Å–ª–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ ({'—Å document' if with_document else '–±–µ–∑ document'}): {len(out)} —Å—Ç—Ä–æ–∫")
    return out


# ========== Upsert ==========
def upsert_stock_tx(conn, rows: list[dict]):
    if not rows:
        print("‚ö†Ô∏è –ù–µ—Ç —Å—Ç—Ä–æ–∫ –¥–ª—è –∑–∞–ø–∏—Å–∏ –≤ –ë–î")
        return 0

    cols = get_table_columns(conn, "stock_tx_iiko", "public")
    has_document = "document" in cols
    turnover_col = pick_turnover_column(cols)

    if not has_document:
        raise RuntimeError("–í stock_tx_iiko –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ document ‚Äî —Ç–µ–∫—É—â–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞")

    rows = aggregate_rows(rows, with_document=True)

    # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ—Ç–æ–∫–∏: —Å –¥–æ–∫—É–º–µ–Ω—Ç–æ–º –∏ –±–µ–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    rows_with_doc = [r for r in rows if r.get("document") not in (None, "")]
    rows_no_doc = [r for r in rows if r.get("document") in (None, "")]

    insert_cols = [
        "department",
        "oper_day",
        "product_num",
        "product_name",
        "product_type",
        "measure_unit",
        "document",
        "transaction_type",
        turnover_col,
        "updated_at",
    ]
    cols_sql = ", ".join(insert_cols)

    placeholders = ["%s"] * (len(insert_cols) - 1)
    template = "(" + ",".join(placeholders) + ",now())"

    total_written = 0

    # ---------- 1) UPSERT –¥–ª—è —Å—Ç—Ä–æ–∫ –° –¥–æ–∫—É–º–µ–Ω—Ç–æ–º ----------
    # –í–ê–ñ–ù–û:
    # - –∫–æ–Ω—Ñ–ª–∏–∫—Ç —Ç–∞—Ä–≥–µ—Ç: (department, product_num, document, transaction_type) WHERE document IS NOT NULL
    # - –ø—Ä–∏ –∞–ø–¥–µ–π—Ç–µ –æ–±–Ω–æ–≤–ª—è–µ–º oper_day (–¥–æ–∫—É–º–µ–Ω—Ç –º–æ–≥ "–ø–µ—Ä–µ–µ—Ö–∞—Ç—å" –Ω–∞ –¥—Ä—É–≥—É—é –¥–∞—Ç—É)
    if rows_with_doc:
        values = []
        for r in rows_with_doc:
            values.append(
                (
                    r.get("department"),
                    r.get("oper_day"),
                    r.get("product_num"),
                    r.get("product_name"),
                    r.get("product_type"),
                    r.get("measure_unit"),
                    r.get("document"),
                    r.get("transaction_type"),
                    float(r.get("turnover") or 0),
                )
            )

        sql_with_doc = f"""
            INSERT INTO stock_tx_iiko ({cols_sql})
            VALUES %s
            ON CONFLICT (department, product_num, document, transaction_type)
            WHERE document IS NOT NULL
            DO UPDATE SET
                oper_day = EXCLUDED.oper_day,
                product_name = EXCLUDED.product_name,
                product_type = EXCLUDED.product_type,
                measure_unit = EXCLUDED.measure_unit,
                {turnover_col} = EXCLUDED.{turnover_col},
                updated_at = now();
        """

        with conn.cursor() as cur:
            execute_values(cur, sql_with_doc, values, template=template, page_size=500)

        conn.commit()
        total_written += len(values)
        print(f"‚úÖ upsert (by doc key) –∑–∞–ø–∏—Å–∞–Ω–æ: {len(values)}")

    # ---------- 2) UPSERT –¥–ª—è —Å—Ç—Ä–æ–∫ –ë–ï–ó –¥–æ–∫—É–º–µ–Ω—Ç–∞ ----------
    # –¢—É—Ç –æ—Å—Ç–∞–≤–ª—è–µ–º ‚Äú—Å—Ç–∞—Ä—É—é‚Äù –ø—Ä–∏–≤—è–∑–∫—É –∫ oper_day, –ø–æ—Ç–æ–º—É —á—Ç–æ –¥–æ–∫—É–º–µ–Ω—Ç = NULL (—É–Ω–∏–∫–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–µ—á–µ–º)
    if rows_no_doc:
        values = []
        for r in rows_no_doc:
            # document –∫–ª–∞–¥—ë–º –∫–∞–∫ None
            values.append(
                (
                    r.get("department"),
                    r.get("oper_day"),
                    r.get("product_num"),
                    r.get("product_name"),
                    r.get("product_type"),
                    r.get("measure_unit"),
                    None,
                    r.get("transaction_type"),
                    float(r.get("turnover") or 0),
                )
            )

        sql_no_doc = f"""
            INSERT INTO stock_tx_iiko ({cols_sql})
            VALUES %s
            ON CONFLICT (department, oper_day, product_num, document, transaction_type)
            DO UPDATE SET
                product_name = EXCLUDED.product_name,
                product_type = EXCLUDED.product_type,
                measure_unit = EXCLUDED.measure_unit,
                {turnover_col} = EXCLUDED.{turnover_col},
                updated_at = now();
        """

        with conn.cursor() as cur:
            execute_values(cur, sql_no_doc, values, template=template, page_size=500)

        conn.commit()
        total_written += len(values)
        print(f"‚úÖ upsert (by day key, doc=NULL) –∑–∞–ø–∏—Å–∞–Ω–æ: {len(values)}")

    return total_written


def print_db_sample(conn, date_from: dt.date, date_to: dt.date):
    cols = get_table_columns(conn, "stock_tx_iiko", "public")
    has_document = "document" in cols
    turnover_col = pick_turnover_column(cols)

    print("üóÑÔ∏è –ü–µ—Ä–≤—ã–µ 10 —Å—Ç—Ä–æ–∫ –∏–∑ –ë–î –∑–∞ –ø–µ—Ä–∏–æ–¥:")

    select_cols = ["department", "oper_day", "product_num"]
    if has_document:
        select_cols.append("document")
    select_cols += ["transaction_type", turnover_col]

    q = f"""
        SELECT {", ".join(select_cols)}
        FROM stock_tx_iiko
        WHERE oper_day >= %s AND oper_day < %s
        ORDER BY oper_day, department, product_num
        LIMIT 10;
    """
    with conn.cursor() as cur:
        cur.execute(q, (date_from, date_to))
        rows = cur.fetchall()
        for i, r in enumerate(rows, start=1):
            print(f"{i:02d}. {r}")


# ========== Refresh DataLens vitrine ==========
def refresh_datalens_tail(conn, date_from: dt.date, date_to: dt.date):
    """
    –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –≤–∏—Ç—Ä–∏–Ω—É batch_daily_lifecycle —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ stock_tx_iiko.

    –í OLAP —É –Ω–∞—Å oper_day –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ: date_from <= oper_day < date_to
    –î–ª—è snapshot_day —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç: date_from .. (date_to - 1) –≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ.
    """
    snapshot_from = date_from
    snapshot_to = date_to - dt.timedelta(days=1)

    if snapshot_to < snapshot_from:
        print("‚ö†Ô∏è –ü–µ—Ä–∏–æ–¥ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –¥–ª—è –ø–µ—Ä–µ—Å—á—ë—Ç–∞ –≤–∏—Ç—Ä–∏–Ω—ã, –ø—Ä–æ–ø—É—Å–∫–∞—é")
        return

    print(f"üßÆ –ü–µ—Ä–µ—Å—á—ë—Ç –≤–∏—Ç—Ä–∏–Ω—ã batch_daily_lifecycle: {snapshot_from} ‚Äî {snapshot_to}")

    with conn.cursor() as cur:
        # 1) –ü—Ä–æ–±—É–µ–º –ø–µ—Ä–µ—Å—á—ë—Ç –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω—É, –µ—Å–ª–∏ –ø—Ä–æ—Ü–µ–¥—É—Ä–∞ –µ—Å—Ç—å
        try:
            cur.execute("CALL public.refresh_batch_daily_lifecycle_range(%s, %s);", (snapshot_from, snapshot_to))
            conn.commit()
            print("‚úÖ –í–∏—Ç—Ä–∏–Ω–∞ –ø–µ—Ä–µ—Å—á–∏—Ç–∞–Ω–∞ —á–µ—Ä–µ–∑ refresh_batch_daily_lifecycle_range")
            return
        except Exception as e:
            conn.rollback()
            print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–∑–≤–∞—Ç—å refresh_batch_daily_lifecycle_range, –ø—Ä–æ–±—É—é fallback:", str(e)[:300])

        # 2) Fallback: –ø–µ—Ä–µ—Å—á—ë—Ç ‚Äú—Ö–≤–æ—Å—Ç–∞‚Äù –ø–æ p_days
        p_days = (snapshot_to - snapshot_from).days + 1
        cur.execute("CALL public.refresh_batch_daily_lifecycle(%s);", (p_days,))
        conn.commit()
        print(f"‚úÖ –í–∏—Ç—Ä–∏–Ω–∞ –ø–µ—Ä–µ—Å—á–∏—Ç–∞–Ω–∞ —á–µ—Ä–µ–∑ refresh_batch_daily_lifecycle(p_days => {p_days})")


# ========== Refresh anchor diffs (Plan/Fact discrepancies) ==========
def refresh_anchor_discrepancies(conn):
    """
    –í–ê–ñ–ù–û–ï –ü–û–í–ï–î–ï–ù–ò–ï (–∫–∞–∫ —Ç—ã –ø—Ä–æ—Å–∏—à—å):
    - —Ç–∞–±–ª–∏—Ü—ã —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π –ü–û–õ–ù–û–°–¢–¨–Æ –ø–µ—Ä–µ—Å–æ–±–∏—Ä–∞—é—Ç—Å—è –∫–∞–∂–¥—ã–π –∑–∞–ø—É—Å–∫ ETL
    - –µ—Å–ª–∏ —è–∫–æ—Ä—è —É–¥–∞–ª–∏–ª–∏/–∏–∑–º–µ–Ω–∏–ª–∏ -> —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è –∏—Å—á–µ–∑–∞—é—Ç/–º–µ–Ω—è—é—Ç—Å—è —Å—Ä–∞–∑—É
    - –µ—Å–ª–∏ —è–∫–æ—Ä–µ–π –Ω–µ—Ç -> —Ç–∞–±–ª–∏—Ü—ã —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –ø—É—Å—Ç—ã–º–∏ (–∞ –Ω–µ ‚Äú–∑–∞–ª–∏–ø–∞—é—Ç‚Äù —Å–æ —Å—Ç–∞—Ä—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏)
    """

    # –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü –µ—â—ë –Ω–µ—Ç ‚Äî –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º (–Ω–æ ETL –Ω–µ –ø–∞–¥–∞–µ—Ç).
    if not table_exists(conn, "batch_manual_anchor", "public"):
        print("‚ÑπÔ∏è batch_manual_anchor –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞—é –ø–µ—Ä–µ—Å—á—ë—Ç —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π")
        return
    if not table_exists(conn, "batch_anchor_diff", "public"):
        print("‚ÑπÔ∏è batch_anchor_diff –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞—é –ø–µ—Ä–µ—Å—á—ë—Ç —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π")
        return
    if not table_exists(conn, "batch_anchor_diff_total", "public"):
        print("‚ÑπÔ∏è batch_anchor_diff_total –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞—é –ø–µ—Ä–µ—Å—á—ë—Ç —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π")
        return
    if not table_exists(conn, "batch_daily_lifecycle", "public"):
        print("‚ÑπÔ∏è batch_daily_lifecycle –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞—é –ø–µ—Ä–µ—Å—á—ë—Ç —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π")
        return

    diff_cols = get_table_columns(conn, "batch_anchor_diff", "public")
    total_cols = get_table_columns(conn, "batch_anchor_diff_total", "public")

    # –°–æ–±–µ—Ä—ë–º INSERT-–∫–æ–ª–æ–Ω–∫–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ ‚Äú–≥–∏–±–∫–æ‚Äù (–Ω–µ –ª–æ–º–∞–µ–º—Å—è, –µ—Å–ª–∏ —É —Ç–µ–±—è –Ω–µ–º–Ω–æ–≥–æ –¥—Ä—É–≥–æ–µ –∏–º—è –ø–æ–ª—è)
    # –ò—Å—Ç–æ—á–Ω–∏–∫:
    #   fact:  public.batch_manual_anchor (qty_fact)
    #   plan:  public.batch_daily_lifecycle (qty_closing –Ω–∞ anchor_day –ø–æ production_day)
    # diff = fact - plan
    def pick_one(cols: set[str], variants: list[str], required: bool = False) -> str | None:
        for v in variants:
            if v in cols:
                return v
        if required:
            raise RuntimeError(f"–ù–µ –Ω–∞—à—ë–ª –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—É—é –∫–æ–ª–æ–Ω–∫—É —Å—Ä–µ–¥–∏ {variants}. –ï—Å—Ç—å: {sorted(cols)}")
        return None

    # batch_anchor_diff columns (–≤–∞—Ä–∏–∞–Ω—Ç—ã –Ω–∞ –≤—Å—è–∫–∏–π)
    c_department = pick_one(diff_cols, ["department"], required=True)
    c_product_num = pick_one(diff_cols, ["product_num"], required=True)
    c_product_name = pick_one(diff_cols, ["product_name"])
    c_anchor_day = pick_one(diff_cols, ["anchor_day"], required=True)
    c_production_day = pick_one(diff_cols, ["production_day"], required=True)

    c_qty_fact = pick_one(diff_cols, ["qty_fact", "fact_qty"], required=True)
    c_qty_plan = pick_one(diff_cols, ["qty_plan", "plan_qty", "qty_planned"])
    c_diff_qty = pick_one(diff_cols, ["diff_qty", "qty_diff", "delta_qty"])

    c_batch_status = pick_one(diff_cols, ["batch_status", "status"])
    c_qty_closing = pick_one(diff_cols, ["qty_closing"])  # –µ—Å–ª–∏ –≤–¥—Ä—É–≥ —Ä–µ—à–∏–ª–∏ —Ö—Ä–∞–Ω–∏—Ç—å plan —Ç—É—Ç –∂–µ
    c_qty_opening = pick_one(diff_cols, ["qty_opening"])
    c_created_at = pick_one(diff_cols, ["created_at"])
    c_updated_at = pick_one(diff_cols, ["updated_at"])

    # batch_anchor_diff_total columns
    tc_department = pick_one(total_cols, ["department"], required=True)
    tc_product_num = pick_one(total_cols, ["product_num"], required=True)
    tc_product_name = pick_one(total_cols, ["product_name"])
    tc_anchor_day = pick_one(total_cols, ["anchor_day"], required=True)

    tc_qty_fact = pick_one(total_cols, ["qty_fact_total", "qty_fact", "fact_qty_total", "fact_qty"])
    tc_qty_plan = pick_one(total_cols, ["qty_plan_total", "qty_plan", "plan_qty_total", "plan_qty"])
    tc_diff_qty = pick_one(total_cols, ["diff_qty_total", "diff_qty", "qty_diff_total", "qty_diff", "delta_qty_total", "delta_qty"])
    tc_created_at = pick_one(total_cols, ["created_at"])
    tc_updated_at = pick_one(total_cols, ["updated_at"])

    print("üß© –ü–µ—Ä–µ—Å—á—ë—Ç —Ç–∞–±–ª–∏—Ü —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π (Plan/Fact) –ø–æ —è–∫–æ—Ä—è–º...")

    with conn.cursor() as cur:
        # 0) –ü–æ–ª–Ω–æ—Å—Ç—å—é –æ—á–∏—â–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π ‚Äî —ç—Ç–æ –∫–ª—é—á –∫ —Ç–≤–æ–µ–º—É —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é ‚Äú—É–±—Ä–∞–ª —è–∫–æ—Ä—è -> –≤—Å—ë –∏—Å—á–µ–∑–ª–æ‚Äù
        try:
            cur.execute("TRUNCATE TABLE public.batch_anchor_diff;")
            cur.execute("TRUNCATE TABLE public.batch_anchor_diff_total;")
            conn.commit()
        except Exception as e:
            conn.rollback()
            raise RuntimeError(f"–ù–µ —Å–º–æ–≥ TRUNCATE —Ç–∞–±–ª–∏—Ü—ã —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π: {e}")

        # 1) –ï—Å–ª–∏ —è–∫–æ—Ä–µ–π –Ω–µ—Ç ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–∞–±–ª–∏—Ü—ã –ø—É—Å—Ç—ã–º–∏ –∏ –≤—ã—Ö–æ–¥–∏–º
        cur.execute("SELECT COUNT(*) FROM public.batch_manual_anchor;")
        anchors_cnt = int(cur.fetchone()[0])
        if anchors_cnt == 0:
            conn.commit()
            print("‚úÖ –Ø–∫–æ—Ä–µ–π –Ω–µ—Ç ‚Äî —Ç–∞–±–ª–∏—Ü—ã —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π –æ—Å—Ç–∞–≤–ª–µ–Ω—ã –ø—É—Å—Ç—ã–º–∏")
            return

        # 2) –°–æ–±–∏—Ä–∞–µ–º detail-—Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è
        # plan –±–µ—Ä—ë–º –∏–∑ batch_daily_lifecycle: qty_closing –Ω–∞ snapshot_day=anchor_day
        # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∏ –≤ lifecycle –Ω–µ—Ç ‚Äî —Å—á–∏—Ç–∞–µ–º –ø–ª–∞–Ω = 0 (–∏–Ω–∞—á–µ –±—É–¥–µ—Ç NULL –∏ —Ä–∞—Å—á—ë—Ç –ª–æ–º–∞–µ—Ç—Å—è)
        insert_cols = [c_department, c_product_num]
        select_exprs = ["a.department", "a.product_num"]

        if c_product_name:
            insert_cols.append(c_product_name)
            # –±–µ—Ä—ë–º –∏–º—è –∏–∑ —è–∫–æ—Ä—è, –Ω–æ –µ—Å–ª–∏ –≤–¥—Ä—É–≥ NULL ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º –∏–∑ prep_items_ref –ø–æ canon_product_num
            select_exprs.append(
                "COALESCE(a.product_name, ref.product_name)"
            )

        insert_cols += [c_anchor_day, c_production_day, c_qty_fact]
        select_exprs += ["a.anchor_day", "a.production_day", "a.qty_fact"]

        # –ø–ª–∞–Ω / –¥–∏—Ñ—Ñ (–µ—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç)
        # qty_plan
        if c_qty_plan:
            insert_cols.append(c_qty_plan)
            select_exprs.append("COALESCE(l.qty_closing, 0)::numeric")

        # diff_qty
        if c_diff_qty:
            insert_cols.append(c_diff_qty)
            select_exprs.append("(a.qty_fact - COALESCE(l.qty_closing, 0))::numeric")

        # –¥–æ–ø. –ø–æ–ª—è (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if c_batch_status:
            insert_cols.append(c_batch_status)
            select_exprs.append("l.batch_status")

        if c_qty_opening:
            insert_cols.append(c_qty_opening)
            select_exprs.append("COALESCE(l.qty_opening, 0)::numeric")

        if c_qty_closing:
            insert_cols.append(c_qty_closing)
            select_exprs.append("COALESCE(l.qty_closing, 0)::numeric")

        if c_created_at:
            insert_cols.append(c_created_at)
            select_exprs.append("now()")

        if c_updated_at:
            insert_cols.append(c_updated_at)
            select_exprs.append("now()")

        sql_detail = f"""
            INSERT INTO public.batch_anchor_diff ({", ".join(insert_cols)})
            SELECT
                {", ".join(select_exprs)}
            FROM public.batch_manual_anchor a
            LEFT JOIN public.batch_daily_lifecycle l
              ON l.department = a.department
             AND l.product_num = a.product_num
             AND l.snapshot_day = a.anchor_day
             AND l.production_day = a.production_day
            LEFT JOIN public.prep_items_ref ref
              ON public.canon_product_num(ref.product_num) = public.canon_product_num(a.product_num);
        """

        try:
            cur.execute(sql_detail)
            conn.commit()
            print("‚úÖ batch_anchor_diff –ø–µ—Ä–µ—Å–æ–±—Ä–∞–Ω–∞")
        except Exception as e:
            conn.rollback()
            raise RuntimeError(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ—Å—á—ë—Ç–∞ batch_anchor_diff: {e}")

        # 3) –°–æ–±–∏—Ä–∞–µ–º total-—Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è (–∞–≥—Ä–µ–≥–∞—Ç –ø–æ —Ç–æ–≤–∞—Ä—É –Ω–∞ anchor_day)
        total_insert_cols = [tc_department, tc_product_num]
        total_select_exprs = ["d.department", "d.product_num"]

        if tc_product_name:
            total_insert_cols.append(tc_product_name)
            # –≤ detail product_name –º–æ–∂–µ—Ç –±—ã—Ç—å NULL ‚Äî –±–µ—Ä—ë–º MAX/COALESCE
            total_select_exprs.append("MAX(d.product_name)")

        total_insert_cols.append(tc_anchor_day)
        total_select_exprs.append("d.anchor_day")

        # —Ñ–∞–∫—Ç/–ø–ª–∞–Ω/–¥–∏—Ñ—Ñ ‚Äî —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∏ –µ—Å—Ç—å
        if tc_qty_fact:
            total_insert_cols.append(tc_qty_fact)
            # detail.qty_fact –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ –µ—Å—Ç—å (–ø–æ –Ω–∞—à–µ–º—É –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–º—É c_qty_fact)
            total_select_exprs.append("SUM(d.qty_fact)::numeric")

        if tc_qty_plan:
            total_insert_cols.append(tc_qty_plan)
            if c_qty_plan:
                total_select_exprs.append("SUM(d.qty_plan)::numeric")
            else:
                # –µ—Å–ª–∏ detail –Ω–µ —Ö—Ä–∞–Ω–∏—Ç qty_plan, —Ç–æ –ø–µ—Ä–µ—Å—á–∏—Ç–∞–µ–º –ø–ª–∞–Ω —á–µ—Ä–µ–∑ join –Ω–∞ lifecycle –ø—Ä—è–º–æ —Ç—É—Ç
                total_select_exprs.append(
                    "SUM(COALESCE(l.qty_closing, 0))::numeric"
                )

        if tc_diff_qty:
            total_insert_cols.append(tc_diff_qty)
            if c_diff_qty:
                total_select_exprs.append("SUM(d.diff_qty)::numeric")
            else:
                # diff = fact - plan
                total_select_exprs.append(
                    "(SUM(d.qty_fact) - SUM(COALESCE(l.qty_closing, 0)))::numeric"
                )

        if tc_created_at:
            total_insert_cols.append(tc_created_at)
            total_select_exprs.append("now()")

        if tc_updated_at:
            total_insert_cols.append(tc_updated_at)
            total_select_exprs.append("now()")

        # –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–ª—è total:
        # - –µ—Å–ª–∏ –≤ detail –µ—Å—Ç—å qty_plan/diff_qty ‚Äî –ø—Ä–æ—Å—Ç–æ –∞–≥—Ä–µ–≥–∏—Ä—É–µ–º detail
        # - –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî –ø–æ–¥—Ç—è–≥–∏–≤–∞–µ–º lifecycle –≤—Ç–æ—Ä—ã–º join‚Äô–æ–º (—á—Ç–æ–±—ã –ø–æ—Å—á–∏—Ç–∞—Ç—å –ø–ª–∞–Ω)
        if c_qty_plan or c_diff_qty:
            sql_total = f"""
                INSERT INTO public.batch_anchor_diff_total ({", ".join(total_insert_cols)})
                SELECT
                    {", ".join(total_select_exprs)}
                FROM public.batch_anchor_diff d
                GROUP BY d.department, d.product_num, d.anchor_day;
            """
        else:
            sql_total = f"""
                INSERT INTO public.batch_anchor_diff_total ({", ".join(total_insert_cols)})
                SELECT
                    {", ".join(total_select_exprs)}
                FROM public.batch_anchor_diff d
                LEFT JOIN public.batch_daily_lifecycle l
                  ON l.department = d.department
                 AND l.product_num = d.product_num
                 AND l.snapshot_day = d.anchor_day
                 AND l.production_day = d.production_day
                GROUP BY d.department, d.product_num, d.anchor_day;
            """

        try:
            cur.execute(sql_total)
            conn.commit()
            print("‚úÖ batch_anchor_diff_total –ø–µ—Ä–µ—Å–æ–±—Ä–∞–Ω–∞")
        except Exception as e:
            conn.rollback()
            raise RuntimeError(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ—Å—á—ë—Ç–∞ batch_anchor_diff_total: {e}")


def main():
    date_from, date_to = get_period()
    print(f"üöÄ ETL STOCK TX: {date_from} ‚Äì {date_to}")
    print(f"üåê IIKO_BASE_URL: {IIKO_BASE_URL}")

    token = get_token()
    try:
        rows = fetch_stock_tx(token, date_from, date_to)

        conn = get_pg_connection()
        try:
            n = upsert_stock_tx(conn, rows)
            print(f"‚úÖ –í stock_tx_iiko upsert'–Ω—É—Ç–æ —Å—Ç—Ä–æ–∫: {n}")
            print_db_sample(conn, date_from, date_to)

            # ‚úÖ 1) –û–±–Ω–æ–≤–ª—è–µ–º –≤–∏—Ç—Ä–∏–Ω—É –¥–ª—è DataLens
            refresh_datalens_tail(conn, date_from, date_to)

            # ‚úÖ 2) –°–†–ê–ó–£ –ü–û–°–õ–ï –≤–∏—Ç—Ä–∏–Ω—ã –ø–µ—Ä–µ—Å–æ–±–∏—Ä–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π –ø–æ —è–∫–æ—Ä—è–º
            #    (–ø–æ–ª–Ω–∞—è –ø–µ—Ä–µ—Å–±–æ—Ä–∫–∞ –∫–∞–∂–¥—ã–π –∑–∞–ø—É—Å–∫ -> —É–¥–∞–ª–∏–ª —è–∫–æ—Ä—è -> —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è –∏—Å—á–µ–∑–ª–∏)
            refresh_anchor_discrepancies(conn)

        finally:
            conn.close()
            print("üîå –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Postgres –∑–∞–∫—Ä—ã—Ç–æ")
    finally:
        logout(token)


if __name__ == "__main__":
    main()
